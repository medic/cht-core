{{- include "cht-chart-4x.validations" . -}}

{{- if not .Values.couchdb.clusteredCouchEnabled }}
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    cht.service: couchdb
  name: cht-couchdb
spec:
  replicas: 1
  selector:
    matchLabels:
      cht.service: couchdb
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        cht.service: couchdb
    spec:
      terminationGracePeriodSeconds: 60
      securityContext:
        runAsUser: 0  # CouchDB requires root for data directory permissions
        fsGroup: 0
      {{- if .Values.toleration }}
      tolerations:
        - key: {{ .Values.toleration.key }}
          operator: {{ .Values.toleration.operator }}
          value: {{ .Values.toleration.value | quote }}
          effect: {{ .Values.toleration.effect }}
      {{- end }}
      {{- if and (hasKey .Values "nodes") (kindIs "map" .Values.nodes) }}
        {{- if hasKey .Values.nodes "single_node_deploy" }}
      nodeSelector:
        kubernetes.io/hostname: {{ .Values.nodes.single_node_deploy }}
        {{- end }}
      {{- end }}
      containers:
        - name: cht-couchdb
          image: "{{ .Values.upstream_servers.docker_registry }}/cht-couchdb:{{ .Values.cht_image_tag }}"
          {{ if eq .Values.cache_images false}}imagePullPolicy: Always{{ end }}
          ports:
            - containerPort: 5984
          env:
{{- include "couchdb.basicEnv" . | nindent 12 }}
            - name: SVC_NAME
              value: couchdb.{{ .Values.namespace }}.svc.cluster.local
          resources:
            requests:
              memory: "512Mi"
              cpu: "200m"
            limits:
              memory: "2Gi"
              cpu: "2000m"
          readinessProbe:
            httpGet:
              path: /_up
              port: 5984
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /_up
              port: 5984
            initialDelaySeconds: 30
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          {{- if eq (toString .Values.cluster_type) "k3s-k3d" }}
          volumeMounts:
            - mountPath: /opt/couchdb/data
              name: couchdb-claim0
              {{- if .Values.couchdb_data.dataPathOnDiskForCouchDB }}
              subPath: {{ .Values.couchdb_data.dataPathOnDiskForCouchDB }}
              {{- end }}
            - mountPath: /opt/couchdb/etc/local.d
              name: couchdb-claim0
              subPath: local.d
          {{- else }}
          volumeMounts:
            - mountPath: /opt/couchdb/data
              name: couchdb-claim0
              {{- if .Values.couchdb_data.dataPathOnDiskForCouchDB }}
              subPath: {{ .Values.couchdb_data.dataPathOnDiskForCouchDB }}
              {{- end }}
            - mountPath: /opt/couchdb/etc/local.d
              name: couchdb-claim0
              subPath: local.d
          {{- end }}
        - name: cht-couchdb-nouveau
          image: "{{ .Values.upstream_servers.docker_registry }}/cht-couchdb-nouveau:{{ .Values.cht_image_tag }}"
          {{ if eq .Values.cache_images false}}imagePullPolicy: Always{{ end }}
          ports:
            - containerPort: 5987
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          readinessProbe:
            tcpSocket:
              port: 5987
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          livenessProbe:
            tcpSocket:
              port: 5987
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          volumeMounts:
            - mountPath: /data/nouveau
              name: couchdb-claim0
              subPath: data
      restartPolicy: Always
      volumes:
        - name: couchdb-claim0
          persistentVolumeClaim:
            claimName: couchdb-claim0
status: {}
{{- end }}

{{- if .Values.couchdb.clusteredCouchEnabled }}
{{- range $i, $e := until (int .Values.clusteredCouch.noOfCouchDBNodes) }}
{{ $nodeNumber := add $i 1 }}
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    cht.service: couchdb-{{ $nodeNumber }}
  name: cht-couchdb-{{ $nodeNumber }}
spec:
  replicas: 1
  selector:
    matchLabels:
      cht.service: couchdb-{{ $nodeNumber }}
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        cht.service: couchdb-{{ $nodeNumber }}
    spec:
      terminationGracePeriodSeconds: 60
      securityContext:
        runAsUser: 0  # CouchDB requires root for data directory permissions
        fsGroup: 0
      {{- if $.Values.toleration }}
      tolerations:
        - key: {{ $.Values.toleration.key }}
          operator: {{ $.Values.toleration.operator }}
          value: {{ $.Values.toleration.value | quote }}
          effect: {{ $.Values.toleration.effect }}
      {{- end }}
      {{- if and (hasKey $.Values "nodes") (kindIs "map" $.Values.nodes) }}
        {{- with index $.Values.nodes (printf "node-%d" $nodeNumber) }}
          {{- if . }}
      nodeSelector:
        kubernetes.io/hostname: {{ . }}
          {{- end }}
        {{- end }}
      {{- end }}
      containers:
      - name: cht-couchdb-{{ $nodeNumber }}
        image: "{{ $.Values.upstream_servers.docker_registry }}/cht-couchdb:{{ $.Values.cht_image_tag }}"
        {{ if eq $.Values.cache_images false}}imagePullPolicy: Always{{ end }}
        ports:
          - containerPort: 5984
        env:
        {{- if ne $nodeNumber 1 }}
          - name: COUCHDB_SYNC_ADMINS_NODE
            valueFrom:
              configMapKeyRef:
                name: couchdb-servers-configmap
                key: COUCHDB_SYNC_ADMINS_NODE
        {{- end }}
{{- include "couchdb.basicEnv" $ | nindent 10 }}
          - name: SVC_NAME
            value: couchdb-{{ $nodeNumber }}.{{ $.Values.namespace }}.svc.cluster.local
          - name: NODE_COUNT
            value: {{ $.Values.clusteredCouch.noOfCouchDBNodes | quote }}
        {{- if eq $nodeNumber 1 }}
          - name: CLUSTER_PEER_IPS
            valueFrom:
              configMapKeyRef:
                name: couchdb-servers-configmap
                key: CLUSTER_PEER_IPS
        {{- end }}
        resources:
          requests:
            memory: "512Mi"
            cpu: "200m"
          limits:
            memory: "2Gi"
            cpu: "2000m"
        readinessProbe:
          httpGet:
            path: /_up
            port: 5984
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /_up
            port: 5984
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        volumeMounts:
        - mountPath: /opt/couchdb/data
          name: couchdb-{{ $nodeNumber }}-claim0
          {{- if $.Values.couchdb_data.dataPathOnDiskForCouchDB }}
          subPath: {{ if contains "%d" $.Values.couchdb_data.dataPathOnDiskForCouchDB }}
                    {{- printf $.Values.couchdb_data.dataPathOnDiskForCouchDB $nodeNumber }}
                    {{- else }}
                    {{- $.Values.couchdb_data.dataPathOnDiskForCouchDB }}
                    {{- end }}
          {{- end }}
        - mountPath: /opt/couchdb/etc/local.d
          name: couchdb-{{ $nodeNumber }}-claim0
          subPath: local.d
      {{- if eq $nodeNumber 1 }}
      - name: cht-couchdb-nouveau
        image: "{{ $.Values.upstream_servers.docker_registry }}/cht-couchdb-nouveau:{{ $.Values.cht_image_tag }}"
        {{ if eq $.Values.cache_images false}}imagePullPolicy: Always{{ end }}
        ports:
          - containerPort: 5987
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        readinessProbe:
          tcpSocket:
            port: 5987
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        livenessProbe:
          tcpSocket:
            port: 5987
          initialDelaySeconds: 20
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        volumeMounts:
        - mountPath: /data/nouveau
          name: couchdb-{{ $nodeNumber }}-claim0
          subPath: data
      {{- end }}
      restartPolicy: Always
      volumes:
      - name: couchdb-{{ $nodeNumber }}-claim0
        persistentVolumeClaim:
          claimName: couchdb-{{ $nodeNumber }}-claim0
status: {}
--- #Don't remove the separator. We need this to separate yamls generated by the range command.
{{- end }}
{{- end }}
